# 西瓜书DATAWHALE学习打卡
## day1-2
---
## 第一章
* regression 回归，预测连续值
* classification 分类
* clustering 聚类，将训练集中的数据按潜在规律分成若干组(cluster 簇)
* 学习任务分为supervised learning监督学习(回归、分类)，unsupervised learning无监督学习（聚类）
* 假设空间：关于数据的潜在规律（假设）的集合，机器学习过程就是在假设空间搜索的过程，目标是找到与训练集匹配的假设。
* 版本空间：有可能有多个假设空间与训练集一致，这些假设空间的集合称为版本空间
* inductive bias 归纳偏好：机器学习算法在学习过程中对某种类型假设的偏好
* 奥卡姆剃刀：若有多个假设与观察一致，则选最简单的那个  

## 第二章

### 评估方法
* 留出法(hold-out),需要保证训练与测试数据的一致性，通常采用分层采样，且通常需要多次随机划分并返回结果的平均值来保证准确性。通常用2/3~4/5的样本用于训练，其余作为测试。
* k折交叉验证法(k-fold cross validation):将数据D分层采样划分出k个大小相似的“互斥子集”，用k-1个子集作为训练集，其余作为测试集，做k次取平均值。k常取10，5，20等。(当数据集D中含有m个样本，k=m时，留一法，LOO，比较精确但是训练开销大)
* 自助法(bootstrapping) 给定包含m个样本的数据集D，每次从D中随机抽一个样本放入采样数据集D'，重复m次。通过自主采样，初始数据集D中约有36.8%($\lim\limits_{m\rightarrow0}(1-\frac{1}{m})^m=\frac{1}{e}\approx0.368$)的样本没出现在采样数据集D'中，将D'作为训练集，D\D' (\为集合减法)用于测试集。自助法在数据量小的时候有效，但由于改变了初始数据集的分布，引入了估计偏差，因此在数据量足够的情况下，留出法和交叉验证法更常见。

### 性能度量
* 衡量模型泛化能力的评价标准

  ### <font color=#87CEEB>回归任务</font>
  
  * 均方误差MSE(mean squared error)
    $$ E(f;D)=\frac{1}{m}\sum_{i=1}^{m}(f(xi)-yi)^2 $$
    $$E(f;D)=\int_{x\sim D}^{}(f(xi)-y)^2p(x)dx$$ 
    
  ### <font color=#87CEEB>分类任务</font>
  * $ \amalg(·) $指示函数，当 · 为真、假时分别取1、0    
  * 错误率
  $$ E(f;D)=\frac{1}{m}\sum_{i=1}^{m}\amalg(f(xi)\neq yi) $$
  $$E(f;D)=\int_{x\sim D}^{}\amalg(f(xi)\neq yi)p(x)dx$$ 
  * 精度
  $$ acc(f;D)=1-E(f;D)=\frac{1}{m}\sum_{i=1}^{m}\amalg(f(xi)= yi) $$
  $$ acc(f;D)=1-E(f;D)=\int_{x\sim D}^{}\amalg(f(xi)=yi)p(x)dx$$ 
  
  * <font color=#FFC0CB>查准率 precision与查全率recall </font>
  
    > 二分类问题中，可以有四种结果
    >|      | 预测正例    |  预测反例  |
    >| --------   | -----:   | :----: |
    >| 真实正例    | TP(真正例)    |   FN(假反例)    |
    >| 真实反例      |FP(假正例)      |   TN(真反例)   |
    
    此时
    $$ 查准率P=\frac{TP}{TP+FP} ~~~~查全率R=\frac{TP}{TP+FN} $$
    
  * 平衡点(Break-Even Point,BEP)，当查准率=查全率时的取值为该学习器的平衡点，越大越优
  1. BEP过于简化，F1度量更常用。
  $$ F1=\frac{2\times P\times R}{P+R}=\frac{2\times TP}{(样例总数)+TP-TN}$$
  2. 但是，有的时候，查准率比查全率更重要(推荐内容),有的时候查全率更重要(抓逃犯)，因此，引入了$\beta$
    $$ F_\beta = \frac{(1+\beta ^2)\times P\times R}{(\beta ^2\times P)+R}$$
    显然，当$\beta$>1时查全率影响大，当$\beta$<1时查准率影响大，$\beta$=1时是F1。 
    
    3. 二分类时，在每个混淆矩阵上分别计算出查准率和查全率，在计算平均值，就可以获得“宏查准率(macro-P)”,"宏查准率(macro-R)",可以推出宏F1
    4. 也可以先将各个混淆矩阵的元素对应取平均，在计算TP等的平均值，得到“微查准率(micro-P)”“微查全率”，可以推出”微F1“
    
    * <font color=#FFC0CB>ROC与AUC</font>
    1. 很多机器学习器产生一个预测概率或实值，然后与分类阈值(threshold)比较，大于为正类，小于为反类，实际上，这就相当于我们把测试数据进行了从最可能到最不可能的排序，然后机器找出一个截断点(cut point)，前一部分为正例，后一部分为反例。因此，排序本身的好坏，体现了学习器一般情况下泛化性能的好坏，ROC便是用于衡量此。
    2. ROC的横轴是假正例率(FPR,False Positive Rate),纵轴是真正例率(TPR)
    $$TPR=\frac{TP}{TP+FN} ~ ~ ~ ~~FPR=\frac{FP}{TN+FP}$$
    ![](https://s3.bmp.ovh/imgs/2021/11/3890c8d9e856dba3.jpeg)
    3. 对角线意味着该模型是“随即猜测”的，点(0，1)是理想情况。
    4. 用AUC(Area Under ROC Curve)，ROC曲线下的面积来衡量模型优劣
    $$ AUC=\frac{1}{2}\sum_{i=1}^{m-1}(x_{i+1}-x_i)·(y_i+y_{i+1})=1-l_{rank} $$
    * <font color=#FFC0CB>代价敏感错误率与代价曲线</font>
    1. 有的时候犯错误的代价是不一样的，比如没识别出好人和没事别出坏人产生的后果是不一样的(非均等代价)，因此可以设置一个代价矩阵(cost matrix)，$cost_{ij}$表示将第i类样本预测为第j类的代价，越大则说明犯错成本越高，$cost_{ii}=0$。以二分类为例，第0类为正例，第1类为反例，D^+,D^-代表样例集D的正例子集和反例子集，则代价敏感的错误率为：
    $$E(f;D;cost)=\frac{1}{m}(\sum_{x_i\in D^+}\amalg(f(x_i)\neq y_i)\times cost_{01}+\sum_{x_i\in D^-}\amalg(f(x_i)\neq y_i)\times cost_{10})$$
    2. 在非均等代价情况下，ROC不能反映学习器的期望总体代价，因此要用代价曲线(cost curve)
    3. 代价曲线的横轴是取值为[0,1]的正例概率代价
    $$ P(+)cost=\frac{p\times cost_{01}}{p\times cost_{01}+(1-p)\times cost_{10}}~~~其中，p为样例为正例的概率$$
    4. 代价曲线的纵轴是取值为[0,1]的归一化代价。
    $$ cost_{norm}=\frac{FNR\times p\times cost_{01}+FPR\times (1-p)\times cost_{10}}{p\times cost_{01}+(1-p)\times cost_{10}}$$
    $$ 其中，FNR是假正例率，FNR=1-FPR$$
    ![](https://s3.bmp.ovh/imgs/2021/11/353251d916b9efac.jpeg)
    ### <font color=#87CEEB>比较检验</font>
    * 对单个学习器泛化性能的检测可以用"二项检验"(一组测试数据)和"t检验"(重复留出法/交叉验证法)。
    * 对不同学习器，可以用交叉验证t检验，但为了保证测试的错误率是泛化错误率，训练集不能重叠，因此需要使用"5Ｘ2交叉验证"
    * McNemar检验
    > 对于二分类问题，可以有如下错误率,当$e_{01}=e_{10}$时，性能相同
    >|      | 算法A正确 |  算法A错误|
    >| --------   | -----:   | :----: |
    >| 算法B正确    | $e_{00} $   |   $e_{01}  $  |
    >| 算法B错误      |$e_{10}$      |   $e_{11}$   |
    > 则｜$e_{01}-e_{10}$｜满足正态分布：
    $$\tau_{\chi^2}=\frac{(｜e_{01}-e_{10}｜-1)^2}{e_{01}+e_{10}}$$
    * Friedman检验和Nemenyi后续检验
    1. 交叉验证和McNemar都是统一数据集上两个学习器的比较，如果遇到多个学习器比较，基于算法排序的Friedman可以更直接。
    2. 先在不同数据集上求出学习器的表现的均值，然后求出他的$\tau_{\chi^2}$,再用如下公式计算，N为数据集个数，k为算法个数：
    $$ \tau_{F}=\frac{(N-1)\tau_{x^2}}{N(k-1)-\tau_{x^2}} $$
    $$如果"所有算法性能相同"假设被拒绝$$
    $$说明算法性能显著不同，需要用后续验证进一步区分$$
    $$如 Nemenyi计算平均序值差别的临界值域$$
    $$ CD=q_{\alpha}\sqrt{\frac{k(k+1)}{6N}}$$
  ![](https://s3.bmp.ovh/imgs/2021/11/eda5f5124c8c0bfd.jpeg)
    ### <font color=#87CEEB>偏差与方差</font>
    * 偏差-方差分解用于解释学习算法的泛化性能
    * 注：$\imath E$代表期望预期，书上那个符号实在是不会打23333
    $$以回归为例,f(x;D)为训练集D上的预测输出，则期望预测为:$$
    $$\bar f(x)=\imath E_{D}[f(x;D)]$$
    $$方差为：var(x)=\imath E_{D}[(f(x;D)-\bar f(x))^2]$$
    $$噪点为：\varepsilon ^2=\imath E_{D}[(y_{D}-y)^2]$$
    $$期望输出与真实标记的差别为偏差bias$$
    $$bias^2(x)=(\bar f(x)-y)^2$$
    $$则泛化误差为：E(f;D)=bias^2(x)+var(x)+\varepsilon ^2$$
    * 偏差度量了算法期望预测与真实结果的偏离程度，即算法的拟合能力
    * 方差度量了同样大小的数据集的变动导致的学习性能变化
    * 噪声刻画期望泛化误差下界，刻画学习本身难度
    * 偏差-方差窘境：起初泛化能力弱，扰动强，偏差起主要 作用，后来泛化能力强，数据扰动会导致方差变化，而偏差变化小(可能会过拟合)
    ![](https://s3.bmp.ovh/imgs/2021/11/82c32b8208f2c26d.jpeg)
    
## Day3-9
  ---
## 第三章 线性模型
* 基本形式
$$ f(x)=w^Tx+b~~~w=(w1;w2;...;w_d)$$
* 线性回归

  1.最小二乘法：求均方误差最小的直线，几何上来讲。就是求一根直线，使样本点平行y轴做的直线到这跟线的距离(欧氏距离)最短，即求$E_{(w,b)}=\sum_{i=1}^{m}(y_i-wx_i-b)^2$最小的直线。
  
  2. 将$E_{(w,b  )}$分别对$w和b$求导,得
  
  $$ w=\frac{\sum_{i=1}^{m}y_i(x_i-\bar x)}{\sum_{i=1}^mx_i^2-\frac{1}{m}(\sum_{i=1}^mx_i)^2} $$
  $$b=\frac{1}{m}\sum_{i=1}^m(y_i-wx_i)$$
  $$其中，\bar x=\frac{1}{m}\sum_{i=1}^mx_i$$
* 对数几率回归     

    1.如果要用线性模型去做分类任务,需要一个单调可微函数将分类任务的真实标记y与线性回归模型的预测值联系起来:sigmoid函数，将z值转化为接近0或1的值。
    $$y=\frac{1}{1+e^{-z}} ~->~y=\frac{1}{1+e^
    
    {-(w^Tx+b)}}$$
    $$ 化简得:ln\frac{y}{1-y}=w^Tx+b,其中，\frac{y}{1-y}为几率$$
    2. 那么
    $$因为 ln\frac{p(y=1|x)}{p(y=0|x)}=w^Tx+b$$
    $$即p(y=1|x)=\frac{e^{w^Tx+b}}{1+e^{w^Tx+b}}~,~~p(y=0|x)=\
    
      frac{1}{1+e^{w^Tx+b}}$$
    3. 因此，可以通过 极大似然法 来估计w和b。
    
* 线性判别分析(LDA)
  1. 基本思想就是找一条直线，将数据投影到直线上后，使得同类样例的投影点尽可能接近，异类样例的投影点尽可能远离。   
  ![](https://s3.bmp.ovh/imgs/2021/11/bd659e02d83d23e1.jpeg)
  
* 多分类学习
  1. 核心思路是将一个多分类问题拆成许多二分类问题。
  2. OvO和OvR：
  
  ![](https://s3.bmp.ovh/imgs/2021/11/051884754d654bcc.jpeg)
  3. MvM：通过纠错输出码ECOC

* 类别不平衡问题
  1. 比如训练集为998个反例和两个正例时，学习器只要返回反例就能达到99.8%的准确率，-这显然是不合理的，因此，只要$\frac{y}{1-y}>\frac{m^+}{m^-}$则预测为正例，令$\frac{y'}{1-y'}>\frac{y}{1-y}\times \frac{m^+}{m^-}$
  
  
    2.这个思路即为“再缩放”，但是，实际上，由于“数据集是真实样本的无偏采样”并不一定成立，因此，常有三种做法：欠采样(把多出的数据去掉，使正反例一样多)，过采样(增加一些例子使正反例一样多)，阈值移动（直接在原始训练集上学习，在训练完预测的时候把$\frac{y'}{1-y'}>\frac{y}{1-y}\times \frac{m^+}{m^-}$嵌入决策过程。
  

## Day 10-12
---
## 决策树

* 核心思想是分治，每个节点负责处理一个子问题。
![](https://s3.bmp.ovh/imgs/2021/11/394bc084963349af.jpeg)
* 划分选择：从A中选择最优划分属性$a_*$; 是决策树的关键，随着划分过程不断进行，我们希望决策树分支节点所包含的样本尽可能属于同一类，即纯度purity越来越高

  1. 信息增益
  $$信息熵 Ent(D)=-\sum_{k=1}^{|y|}p_k\log_2p_k ~~~p_k是D中第k类所占比例$$
  $$Ent(D)越小，D纯度越高$$
  $$定义"信息增益"来描述用属性a对样本D进行划分的情况：$$
  $$样本数量越多的分支节点影响越大$$
  $$Gain(D,a)=Ent(D)-\sum_{v=1}^V \frac{|D^v|}{|D|}Ent(D^v)$$
  $$信息增益越大，意味着用属性a来划分得到的纯度提升越大，即算法为：$$
  $$a_*=argmaxGain(D,a)$$
  
  2. 增益率：如果一个属性有很多个可取值，但是，每个可取值只有一个样本，(比如编号)，那么这个属性的分支的纯度很高，信息增益便会偏向他，但这样是没有泛化能力的。即信息增益会偏向于可取值数目较多的属性。使用增益率则与之相反，偏好可取值数少的属性。
  $$Gain_ratio(D,a)=\frac{Gain(D,a)}{IV(a)}$$
  $$ IV(a)=-\sum_{v=1}{V} \frac{|D^v|}{|D|}\log_2 \frac{|D^v|}{|D|}  $$
  $$C4.5决策树算法先从候选划分属性中找出信息增益高于平均水平的属性$$
  $$再从中选择增益率最高的$$
  
  3.基尼指数：CART决策树使用基尼指数来选择划分属性，反应了从数据集D中随机抽取两个样本，其类别标记不一致的概率，因此，Gini(D)越小，则数据集D的纯度越高。
  $$Gini(D)=\sum_{k=1}^{|y|}\sum_{k'\neq k}p_kp_{k'}=1-\sum_{k=1}^{|y|}p^2_k$$
  $$Gini\_index(D,a)=\sum_{v=1}^{V}\frac{|D^v|}{|D|}Gini(D^v)$$

* 剪枝处理

   1.剪枝处理是为了防止发生过拟合情况，即分支过多。
   
   2.预剪枝：基于贪心，有欠拟合风险，但速度快
        
   ![](https://s3.bmp.ovh/imgs/2021/11/a89a0a36060d0523.jpeg)
   
   3. 后剪枝：在整棵决策树完成以后，进行剪枝，欠拟合效果好，泛化性能好。但要
   
   考察所有节点分支，时间耗费极大
   ![](https://s3.bmp.ovh/imgs/2021/11/3535bde39b344840.jpeg)
   
* 连续与缺失值

   1. 如果遇到连续属性，那么就有可取值有无穷多个，这个时候，通过二分可以找到最优划分点
   $$ T_a=\{\frac{a^i+a^{i+1}}{2}|1\leq i\leq n-1 \}$$
   $$此时，Gain(D,a)=\underset {t\in T_a}{max} Gain(D,a,t)=\underset {t\in T_a}{max}Ent(D)-\sum_{\lambda \in \{-,+\}}\frac{|D_t^{\lambda}|}{D}Ent(D_t^{\lambda})$$
   2. 缺失值处理，给每个样本x赋予一个权重$w_x$,并定义：
   $$p=\frac{\sum_{x\in \tilde{D}}w_x}{\sum_{x\in D}w_x}~~~p为无缺失值所占比例$$
   $$\tilde{p}_k=\frac{\sum_{x\in \tilde{D}_k}w_x}{\sum_{x\in D}w_x} ~ ~ ~(1\leq k\leq |y|) ~~~ \tilde{p}_k为缺失值样本所占比例 $$
   $$\tilde{r}_v=\frac{\sum_{x\in \tilde{D}_v}w_x}{\sum_{x\in D}w_x} ~ ~ ~(1\leq v\leq V) ~~~\tilde{r}_v表示无缺失值样本在属性a上取值a^v的样本所占比例   $$
   $$ 则此时，Gain(D,a)=p\times Gain(\tilde{D},a)=p\times (Ent(\tilde{D})-\sum_{v=1}^{V}\tilde{r}_vEnt(\tilde{D}^v)) $$
   $$ Ent(\tilde{D})=-\sum_{k=1}^{|y|}\tilde{p}_klog_2\tilde{p}_k $$
   
   
* 多变量决策树：当真实分类边界比较复杂时，需要使用很多段划分才能取得很好的结果，此时，用斜的划分边界可以大大简化决策树，因此，每个非叶节点可以使用线性分类器。

## Day13-15
---
## 神经网络
![](https://s3.bmp.ovh/imgs/2021/12/52aec710c4d506cb.jpeg)

* 感知机与多层网络：感知机有两层神经网络组成，不能解决异或和线性可分问题，只能解决与或非之类的简单问题，因此要使用多层前馈神经网络

* BP误差逆传播算法训练多层前馈神经网络
![](https://s3.bmp.ovh/imgs/2021/12/c9bba1124dfff6f0.jpeg)
$$ 输出层第j个神经元阈值用\theta_j来表示，隐藏层第h个神经元阈值用\gamma _h表示$$
$$输入层第i个神经元与隐藏层第h个神经元之间的连接权为v_{ih}$$
$$隐藏层第h个神经元与输出层第j个神经元之间的连接权为w_{hj}$$
$$训练例(x_k,y_k),神经网络的输出为：\tilde{y}^k_j=f(\beta_j-\theta_j)$$
$$则均方误差MSE:E_k=\frac{1}{2}\sum_{j=1}^{l}(\tilde{y}_j^k-y_j^k)^2$$
$$以图5.7为例，\eta 为学习率，则\Delta w_{hj}=-\eta \frac{\partial E_k}{\partial W_{hj}}$$
$$w_{hj}先影响第j个神经元的输入值\beta_j,在影响输出值\tilde{y}^k_j,最后影响E_k，即链式法则$$
$$\frac{\partial E_k}{\partial W_{hj}}=\frac{\partial E_k}{\partial \tilde{y}^k_j}\times \frac{\partial \tilde{y}^k_j}{\partial \beta _j}\times \frac{\partial \beta _j}{\partial w_{hj}}$$
$$ 因为\beta_j的定义：b_h=\frac{\partial \beta_j}{\partial w_{hj}}$$
$$且Sigmod：f(x)=\frac{1}{1+e^{-x}}~~~f'(x)=f(x)(1-f(x))$$
$$所以，梯度g_j：g_j=-\frac{\partial E_k}{\partial \tilde{y}^k_j}\times \frac{\partial \tilde{y}^k_j}{\partial \beta _j}=-(\tilde{y}_j^k-y_j^k)^2f'(\beta_j-\theta_j)=\tilde{y}_j^k(1-\tilde{y}_j^k)(y_j^k-\tilde{y}_j^k)$$
$$ \Delta w_{hj}=\eta g_jb_h~~~\Delta \theta_j=-\eta g_j~~~\Delta v_{ih}=\eta e_h x_i~~~\Delta \gamma_h=-\eta e_h$$
$$其中，e_h为：e_h=-\frac{\partial E_k}{\partial b_h}\times \frac{\partial b_h}{\partial \alpha_h}=b_h(1-b_h)\sum_{j=1}^{l}w_{hj}g_j$$
![](https://s3.bmp.ovh/imgs/2021/12/4ae26a170b6e0cf3.jpeg)
* bp的拟合能力非常强大，因此常常有过拟合风险，因此采用：

  1.早停：将数据分成训练集和验证集，在训练集上训练，若训练集误差降低但验证集误差升高，就停止训练。
  
  2.正则化：在误差目标函数中增加一个用于描述网络复杂度的部分，如连接权与阈值的平方和
  $$ E=\lambda \frac{1}{m}\sum_{k=1}^mE_k+(1-\lambda )\sum_{i}w_i^2$$
  更改后训练过程会偏好比较小的连接权和阈值，使网络输出更加光滑。





   
   
