{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3026a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "import numpy as np\n",
    "#这个函数用来统计得到一个总体单词向量，即所有的文本一共有多少个不同的单词\n",
    "#由这些不同的单词组成一个单词向量，向量可以理解为列表\n",
    "#dataSet:训练数据集\n",
    "def createVocabList(dataSet):\n",
    "   #使用PythonI内置setO函数创建一个空的集合，用来保存数据集的单词向量，集合里面的元素都是独一无二的\n",
    "    vocabSet =set([])\n",
    "    #使用for循环逐行地读取数据集\n",
    "    for document in dataSet:\n",
    "        #set (document）:将当前这一行数据去重，得到这行数据的单词向量\n",
    "        #然后通过集合的或运算（和数学的集合或运算一样），把当前行的单词向量保存到集合vocabSet中\n",
    "        #在保存到集合vocabSet前，都要把当前的集合vocabSet与当前的行的单词向量se（document）做集合的或运算处理\n",
    "        #目的是保证每次最后保存到集合vocabSet中的单词都是独一无二的\n",
    "\n",
    "        vocabSet=vocabSet|set(document)\n",
    "    #最后将集合vocabSet变为列表类型的数据返回\n",
    "    return list(vocabSet)\n",
    "#这个函数用来获取训练数据集和标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00ea1c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据集规模:\n",
      "(5,)\n",
      "输出训练数据集：\n",
      "[['a', 'great', 'game'], ['the', 'election', 'was', 'over'], ['very', 'clean', 'match'], ['a', 'clean', 'but', 'forgettable', 'game'], ['it', 'was', 'a', 'close', 'election']]\n",
      "输出训练数据集标签：\n",
      "[1, 0, 1, 1, 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\ML\\lib\\site-packages\\numpy\\core\\fromnumeric.py:1970: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = asarray(a).shape\n"
     ]
    }
   ],
   "source": [
    "def loadDataSet():\n",
    "    postingList=[['a','great','game'],\n",
    "                    ['the','election','was','over'],\n",
    "                    ['very','clean','match'],\n",
    "                    ['a','clean','but','forgettable','game'],\n",
    "                    ['it','was','a','close','election']]\n",
    "    classVec=[1,0,1,1,0]\n",
    "    return postingList,classVec\n",
    "dataSet,labels =loadDataSet()\n",
    "#验证数据集规模和数据集标签\n",
    "print('训练数据集规模:')\n",
    "print(np.shape(dataSet))\n",
    "print('输出训练数据集：')\n",
    "print(dataSet)\n",
    "print('输出训练数据集标签：')\n",
    "print(labels)\n",
    "#这个函数的作用是将原来文本的一条记录,转变为与单词向量一样长度的、只有0和1两种值的一条数据记录\n",
    "#vocabList:原数据集单词向量\n",
    "#inputSet:数据集的一条文本记录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7b785fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def setOfWords2Vec(vocabList,inputSet):\n",
    "    #生成一个长度与单词向量一样的列表,里面的元素默认都是0\n",
    "    returnVec=[0]*len(vocabList)\n",
    "    #逐个地把每条记录的单词读出来\n",
    "    for word in inputSet:\n",
    "        #判断这个单词在单词向量中是否存在\n",
    "        if word in vocabList:\n",
    "            #如果这个单词存在单词向量中,就获取这个单词所在单词向量的位置索引vocabListindex(word)\n",
    "            #然后根据这个索引,把returnVec的对应位置索引的值修改为1\n",
    "            returnVec[vocabList.index(word)]=1\n",
    "        else:\n",
    "    #如果这个单词不存在单词向量中,输出一条提示的信息,说明该单词不在单词向量中(向量和列是一样的)\n",
    "            print(\"the word:%s is not in my Vocabulary！\"%word)\n",
    "\n",
    "    #将这条转换得到的数据返回\n",
    "    return returnVec\n",
    "#这个函数的作用是获取原数据集类别的概率和数据集每种类别对应的特征的概率\n",
    "#trainMatrix:转换后的数据集\n",
    "#trainCategory:数据集的标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d59dc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainNB0(trainMatrix,trainCategory):\n",
    "    #取得数据集行数\n",
    "    numTrainDocs=len(trainMatrix)\n",
    "    #取得数据集列数\n",
    "    numWords=len(trainMatrix[0])\n",
    "    #计算标签列为1的概率\n",
    "    pAbusive=sum(trainCategory)/float(numTrainDocs)\n",
    "    #生成一个变量用来保存属于这个类别的记录的所有特征对应位置累加的结果,现在默认里面的数值都是\n",
    "    p0Num=np.ones(numWords)\n",
    "    #生成一个变量用来保存属于1这个类别的记录的所有特征对应位置累加的结果,现在默认里面的数值都是\n",
    "    p1Num=np.ones(numWords)\n",
    "    #定义一个变量用来保存属于0这个类别的所有记录的所有元素的累加和,默认初始值是2\n",
    "    p0Denom=2.0\n",
    "    #定义一个变量用来保存属于1这个类别的所有记录的所有元素的累加和,默认初始值是2\n",
    "    p1Denom=2.0\n",
    "    #使用for循环按行读取转换后的数据集\n",
    "    for i in range(numTrainDocs):\n",
    "        #如果当前行的数据记录是属于1这个类别的\n",
    "        if trainCategory[i]==1:\n",
    "            #就把这一条数据记录中的各个元素对应累加到plNum中\n",
    "            p1Num+=trainMatrix[i]\n",
    "            #把这条数据记录中的所有元素都累加到plDenom中\n",
    "            p1Denom+=sum(trainMatrix[i])\n",
    "        else:\n",
    "            #如果当前行的数据记录是属于0这个类别的\n",
    "            #就把这一条数据记录中的各个元素对应累加到pONum中\n",
    "            p0Num+=trainMatrix[i]\n",
    "            #把这条数据记录中的所有元素都累加到poDenom中\n",
    "            p0Denom+=sum(trainMatrix[i])\n",
    "    #球得1这个类别对应各个特征的率Denom,并且对这个概率取对数,使得每个特征性对家绝对值不那么小\n",
    "    p1Vect=np.log(p1Num/p1Denom)\n",
    "    #得0这个对应各个特的率pN0并且对这个极率取对数,使得每个特征属性动绝对值不那么小\n",
    "    p0Vect=np.log(p0Num/p0Denom)\n",
    "    #p0Vect:0这个类别对应每个特征属性的概率取值(使用log函数处理了一下)\n",
    "    #p1Vect:1这个类别对应每个特征属性的概率取值(使用log函数处理了一下)\n",
    "    #pAbusive:标签列为1的概率\n",
    "    return p0Vect,p1Vect,pAbusive\n",
    "#vec2Classify:未知标签的数据记录\n",
    "#p0Vec:0标签对应32个属性的概率\n",
    "#p1Vec:1标签对应32个属性的概率\n",
    "#pClass1:1标签所占的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92c14b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyNB(vec2Classify,p0Vec,p1Vec,pClass1):\n",
    "    #vec2 Classify*pIVec:将这个未知标签的记录中每个元素对应乘以一个概率\n",
    "    #然后再使用sum()函数求所有乘积的累加和sum(vec2Classify*plVec)\n",
    "    #之后再加上原数据集1这个类别标签概率的对数\n",
    "    #最后得到的pl是：这条vec2Classify未知标签数据记录属于1这个类别的概率大小\n",
    "    p1=sum(vec2Classify*p1Vec)+np.log(pClass1)\n",
    "    #vec2Classify*p0Vec:将这个未知标签的记录中每个元素对应乘以一个概率\n",
    "    #然后再使用sumO函数求所有乘积的累加和sum(vec2 Classify*p0Vec)\n",
    "    #之后再加上原数据集0这个类别标签概率的对数\n",
    "    #最后得到的p0是：这条vec2 Classify未知标签数据记录属于0这个类别的概率的大小\n",
    "    p0=sum(vec2Classify*p0Vec)+np.log(1.0-pClass1)\n",
    "    #如果pl>p0\n",
    "    if p1>p0:\n",
    "        #那么返回这个未知标签的记录的预测标签是1\n",
    "        return 1\n",
    "    else:#否则预测标签就是0\n",
    "        return 0\n",
    "#这个函数是用来测试算法的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb2da298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testingNB():\n",
    "    #加载上面的训练数据集,对应的标签列\n",
    "    listOPosts,listClasses=loadDataSet()\n",
    "    #根据训练数据集得到数据集的单词向量,里面的每个单词都是独一无二的\n",
    "    myVocabList=createVocabList(listOPosts)\n",
    "    #定义一个列表,用来保存将原数据集转换之后的数据记录,然后把这个列表数据集当成训练数据集\n",
    "    trainMat=[]\n",
    "    #使用for循环逐行地读取原数据集\n",
    "    for postinDoc in listOPosts:\n",
    "        #setOfWords22Vec(my VocabList,postinDoc:根据单词向量把当前这条原记录变成另一种数据记录形式\n",
    "        #然后把这条转换得到的数据集记录保存到trainMat中\n",
    "        trainMat.append(setOfWords2Vec(myVocabList,postinDoc))\n",
    "    #np.array(trainMat):将数据集的数据集类型变成数组类型\n",
    "    #np.arraye(listClasses):将数据集的标签类型变成数组类型\n",
    "    #调用trainNBOO函数获取新的训练数据集\n",
    "    #0这个类别对应每个特征属性的概率取值p0V(使用log函数处理了一下)\n",
    "    #1这个类别对应每个特征属性的概率取值plV(使用10g函数处理了一下)\n",
    "    #标签列为1的概率pAb\n",
    "    p0V,p1V,pAb=trainNB0(np.array(trainMat),np.array(listClasses))\n",
    "    #testEntry:一条未知标签的原文本数据\n",
    "    testEntry =['a','very','close','game']\n",
    "    #调用setofwordsa2VecO函数根据单词列表来对这条测试文本数据的数据形式进行转化\n",
    "    #最后把得到的这个数据记录再转变成数组类型的数据记录\n",
    "    thisDoc=np.array(setOfWords2Vec(myVocabList,testEntry))\n",
    "    #调用classifyNBOE函数来获取该测试数据记录的标签\n",
    "    #并且输出这条记录数据的最后预测标签类别\n",
    "    print(testEntry,'classified as:',classifyNB(thisDoc,p0V,p1V,pAb))\n",
    "    #这是第二条文本测试记录\n",
    "\n",
    "    testEntry = ['a','very','close','election']\n",
    "    #调用setOfWords2Vec()函数根据单词列表来对这条测试文本数据的数据形式进行转化\n",
    "    #最后把得到的这个数据记录再转变成数组类型的数据记录\n",
    "    thisDoc=np.array(setOfWords2Vec(myVocabList,testEntry))\n",
    "    #调用 classifyNBO函数来获取该测试数据记录的标签\n",
    "    #并且输出这条记录数据的最后预测标签类别\n",
    "    print(testEntry,'classified as: ',classifyNB(thisDoc,p0V,p1V,pAb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a887829",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'very', 'close', 'game'] classified as: 1\n",
      "['a', 'very', 'close', 'election'] classified as:  0\n"
     ]
    }
   ],
   "source": [
    "#调用testingNBO这个函数,开始测试性预测\n",
    "testingNB()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
