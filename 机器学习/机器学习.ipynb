{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40ec790f",
   "metadata": {},
   "source": [
    "### id3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dc01154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0个特征的增益为0.549\n",
      "第1个特征的增益为0.159\n",
      "第2个特征的增益为0.360\n",
      "第0个特征的增益为0.311\n",
      "第1个特征的增益为0.811\n",
      "{'工资': {0: {'育儿': {0: 'no', 1: 'yes', 2: 'yes'}}, 1: 'no'}}\n",
      "放贷\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "from math import log\n",
    "import operator\n",
    " \n",
    " \n",
    " \n",
    "\"\"\"\n",
    "函数说明:创建测试数据集\n",
    "\"\"\"\n",
    "def createDataSet():\n",
    "    '''\n",
    "   \n",
    "  \n",
    "  '''\n",
    "    dataSet = [[1,1,2,'no'],\n",
    "               [0,1,0,'no'],\n",
    "               [1,0,0,'no'],\n",
    "               [1,1,0,'no'],\n",
    "               [0,1,1,'yes'],\n",
    "               [1,1,1,'no'],\n",
    "               [0,0,2,'yes'],\n",
    "               [0,0,1,'yes']]\n",
    "    labels = ['工资', '婚姻', '育儿']        #分类属性\n",
    "    return dataSet, labels                           #返回数据集和分类属性\n",
    " \n",
    " \n",
    "\"\"\"\n",
    "函数说明:计算给定数据集的经验熵(香农熵)\n",
    "Parameters:\n",
    "    dataSet - 数据集\n",
    "Returns:\n",
    "    shannonEnt - 经验熵(香农熵)\n",
    "\"\"\"\n",
    "def calcShannonEnt(dataSet):\n",
    "    numEntires = len(dataSet)                        #返回数据集的行数\n",
    "    labelCounts = {}                                 #保存每个标签(Label)出现次数的字典\n",
    "    for featVec in dataSet:                          #对每组特征向量进行统计\n",
    "        currentLabel = featVec[-1]                   #提取标签(Label)信息\n",
    "        if currentLabel not in labelCounts.keys():   #如果标签(Label)没有放入统计次数的字典,添加进去\n",
    "            labelCounts[currentLabel] = 0\n",
    "        labelCounts[currentLabel] += 1               #Label计数\n",
    "    shannonEnt = 0.0                                 #经验熵(香农熵)\n",
    "    for key in labelCounts:                          #计算香农熵\n",
    "        prob = float(labelCounts[key]) / numEntires  #选择该标签(Label)的概率\n",
    "        shannonEnt -= prob * log(prob, 2)            #利用公式计算\n",
    "    return shannonEnt                                #返回经验熵(香农熵)\n",
    " \n",
    " \n",
    "\"\"\"\n",
    "函数说明:按照给定特征划分数据集\n",
    "Parameters:\n",
    "    dataSet - 待划分的数据集\n",
    "    axis - 划分数据集的特征\n",
    "    value - 需要返回的特征的值\n",
    "\"\"\"\n",
    "def splitDataSet(dataSet, axis, value):\n",
    "    retDataSet = []                                     #创建返回的数据集列表\n",
    "    for featVec in dataSet:                             #遍历数据集\n",
    "        if featVec[axis] == value:\n",
    "            reducedFeatVec = featVec[:axis]             #去掉axis特征\n",
    "            reducedFeatVec.extend(featVec[axis+1:])     #将符合条件的添加到返回的数据集\n",
    "            retDataSet.append(reducedFeatVec)\n",
    "    return retDataSet                                   #返回划分后的数据集\n",
    " \n",
    " \n",
    "\"\"\"\n",
    "函数说明:选择最优特征\n",
    "Parameters:\n",
    "    dataSet - 数据集\n",
    "Returns:\n",
    "    bestFeature - 信息增益最大的(最优)特征的索引值\n",
    "\"\"\"\n",
    "def chooseBestFeatureToSplit(dataSet):\n",
    "    numFeatures = len(dataSet[0]) - 1                     #特征数量\n",
    "    baseEntropy = calcShannonEnt(dataSet)                 #计算数据集的香农熵\n",
    "    bestInfoGain = 0.0                                    #信息增益\n",
    "    bestFeature = -1                                      #最优特征的索引值\n",
    "    for i in range(numFeatures):                          #遍历所有特征\n",
    "        #获取dataSet的第i个所有特征\n",
    "        featList = [example[i] for example in dataSet]\n",
    "        uniqueVals = set(featList)                         #创建set集合{},元素不可重复\n",
    "        newEntropy = 0.0                                   #经验条件熵\n",
    "        for value in uniqueVals:                           #计算信息增益\n",
    "            subDataSet = splitDataSet(dataSet, i, value)           #subDataSet划分后的子集\n",
    "            prob = len(subDataSet) / float(len(dataSet))           #计算子集的概率\n",
    "            newEntropy += prob * calcShannonEnt(subDataSet)        #根据公式计算经验条件熵\n",
    "        infoGain = baseEntropy - newEntropy                        #信息增益\n",
    "        print(\"第%d个特征的增益为%.3f\" % (i, infoGain))             #打印每个特征的信息增益\n",
    "        if (infoGain > bestInfoGain):                              #计算信息增益\n",
    "            bestInfoGain = infoGain                                #更新信息增益，找到最大的信息增益\n",
    "            bestFeature = i                                        #记录信息增益最大的特征的索引值\n",
    "    return bestFeature                                             #返回信息增益最大的特征的索引值\n",
    " \n",
    " \n",
    "\"\"\"\n",
    "函数说明:统计classList中出现此处最多的元素(类标签)\n",
    "Parameters:\n",
    "    classList - 类标签列表\n",
    "Returns:\n",
    "    sortedClassCount[0][0] - 出现此处最多的元素(类标签)\n",
    "\"\"\"\n",
    "def majorityCnt(classList):\n",
    "    classCount = {}\n",
    "    for vote in classList:                                        #统计classList中每个元素出现的次数\n",
    "        if vote not in classCount.keys():\n",
    "            classCount[vote] = 0\n",
    "        classCount[vote] += 1\n",
    "    sortedClassCount = sorted(classCount.items(), key = operator.itemgetter(1), reverse = True)        #根据字典的值降序排序\n",
    "    return sortedClassCount[0][0]                                #返回classList中出现次数最多的元素\n",
    " \n",
    " \n",
    "\"\"\"\n",
    "函数说明:递归构建决策树\n",
    "Parameters:\n",
    "    dataSet - 训练数据集\n",
    "    labels - 分类属性标签\n",
    "    featLabels - 存储选择的最优特征标签\n",
    "Returns:\n",
    "    myTree - 决策树\n",
    "\"\"\"\n",
    "def createTree(dataSet, labels, featLabels):\n",
    "    classList = [example[-1] for example in dataSet]               #取分类标签(是否放贷:yes or no)\n",
    "    if classList.count(classList[0]) == len(classList):            #如果类别完全相同则停止继续划分\n",
    "        return classList[0]\n",
    "    if len(dataSet[0]) == 1:                                       #遍历完所有特征时返回出现次数最多的类标签\n",
    "        return majorityCnt(classList)\n",
    "    bestFeat = chooseBestFeatureToSplit(dataSet)                   #选择最优特征\n",
    "    bestFeatLabel = labels[bestFeat]                               #最优特征的标签\n",
    "    featLabels.append(bestFeatLabel)\n",
    "    myTree = {bestFeatLabel:{}}                                    #根据最优特征的标签生成树\n",
    "    del(labels[bestFeat])                                          #删除已经使用特征标签\n",
    "    featValues = [example[bestFeat] for example in dataSet]        #得到训练集中所有最优特征的属性值\n",
    "    uniqueVals = set(featValues)                                   #去掉重复的属性值\n",
    "    for value in uniqueVals:\n",
    "        subLabels=labels[:]\n",
    "        #递归调用函数createTree(),遍历特征，创建决策树。\n",
    "        myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet, bestFeat, value), subLabels, featLabels)\n",
    "    return myTree\n",
    " \n",
    " \n",
    "\"\"\"\n",
    "函数说明:使用决策树执行分类\n",
    "Parameters:\n",
    "    inputTree - 已经生成的决策树\n",
    "    featLabels - 存储选择的最优特征标签\n",
    "    testVec - 测试数据列表，顺序对应最优特征标签\n",
    "Returns:\n",
    "    classLabel - 分类结果\n",
    "\"\"\"\n",
    "def classify(inputTree, featLabels, testVec):\n",
    "    firstStr = next(iter(inputTree))             #获取决策树结点\n",
    "    secondDict = inputTree[firstStr]             #下一个字典\n",
    "    featIndex = featLabels.index(firstStr)\n",
    "    for key in secondDict.keys():\n",
    "        if testVec[featIndex] == key:\n",
    "            if type(secondDict[key]).__name__ == 'dict':\n",
    "                classLabel = classify(secondDict[key], featLabels, testVec)\n",
    "            else:\n",
    "                classLabel = secondDict[key]\n",
    "    return classLabel\n",
    " \n",
    "if __name__ == '__main__':\n",
    "    dataSet, labels = createDataSet()\n",
    "    featLabels = []\n",
    "    myTree = createTree(dataSet, labels, featLabels)\n",
    "    print(myTree)\n",
    "    testVec = [0, 1]     # 测试数据\n",
    "    result = classify(myTree, featLabels, testVec)\n",
    "    if result == 'yes':\n",
    "        print('放贷')\n",
    "    if result == 'no':\n",
    "        print('不放贷')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507e5911",
   "metadata": {},
   "source": [
    "### 可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3450680f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    " #定义文本框和箭头格式\n",
    "decisionNode=dict(boxstyle='sawtooth',fc='0.8')\n",
    "leafNode=dict(boxstyle='round4',fc='0.8')\n",
    "arrow_args=dict(arrowstyle='<-')\n",
    "#设置中文字体\n",
    "font = FontProperties(fname=r\"c:\\windows\\fonts\\simsun.ttc\", size=14)\n",
    " \n",
    " \n",
    "\"\"\"\n",
    "函数说明:获取决策树叶子结点的数目\n",
    "Parameters:\n",
    "    myTree - 决策树\n",
    "Returns:\n",
    "    numLeafs - 决策树的叶子结点的数目\n",
    "\"\"\"\n",
    "def getNumLeafs(myTree):\n",
    "    numLeafs = 0                   #初始化叶子\n",
    "    # python3中myTree.keys()返回的是dict_keys,不在是list,所以不能使用myTree.keys()[0]的方法获取结点属性，\n",
    "    # 可以使用list(myTree.keys())[0]\n",
    "    firstStr = next(iter(myTree))\n",
    "    secondDict = myTree[firstStr]                      #获取下一组字典\n",
    "    for key in secondDict.keys():\n",
    "        if type(secondDict[key]).__name__=='dict':     #测试该结点是否为字典，如果不是字典，代表此结点为叶子结点\n",
    "            numLeafs += getNumLeafs(secondDict[key])\n",
    "        else:\n",
    "            numLeafs +=1\n",
    "    return numLeafs\n",
    " \n",
    " \n",
    "\"\"\"\n",
    "函数说明:获取决策树的层数\n",
    "Parameters:\n",
    "    myTree - 决策树\n",
    "Returns:\n",
    "    maxDepth - 决策树的层数\n",
    "\"\"\"\n",
    "def getTreeDepth(myTree):\n",
    "    maxDepth = 0                                  #初始化决策树深度\n",
    "    # python3中myTree.keys()返回的是dict_keys,不在是list,所以不能使用myTree.keys()[0]的方法获取结点属性，\n",
    "    # 可以使用list(myTree.keys())[0]\n",
    "    firstStr = next(iter(myTree))\n",
    "    secondDict = myTree[firstStr]                          #获取下一个字典\n",
    "    for key in secondDict.keys():\n",
    "        if type(secondDict[key]).__name__=='dict':         #测试该结点是否为字典，如果不是字典，代表此结点为叶子结点\n",
    "            thisDepth = 1 + getTreeDepth(secondDict[key])\n",
    "        else:\n",
    "            thisDepth = 1\n",
    "        if thisDepth > maxDepth:\n",
    "            maxDepth = thisDepth      #更新层数\n",
    "    return maxDepth\n",
    " \n",
    " \n",
    "\"\"\"\n",
    "函数说明:绘制结点\n",
    "Parameters:\n",
    "    nodeTxt - 结点名\n",
    "    centerPt - 文本位置\n",
    "    parentPt - 标注的箭头位置\n",
    "    nodeType - 结点格式\n",
    "\"\"\"\n",
    "def plotNode(nodeTxt, centerPt, parentPt, nodeType):\n",
    "    arrow_args = dict(arrowstyle=\"<-\")                                          #定义箭头格式\n",
    "    font = FontProperties(fname=r\"c:\\windows\\fonts\\simsun.ttc\", size=14)        #设置中文字体\n",
    "    createPlot.ax1.annotate(nodeTxt, xy=parentPt,  xycoords='axes fraction',    #绘制结点\n",
    "                            xytext=centerPt, textcoords='axes fraction',\n",
    "                            va=\"center\", ha=\"center\", bbox=nodeType, arrowprops=arrow_args,fontproperties=font)\n",
    " \n",
    " \n",
    "\"\"\"\n",
    "函数说明:标注有向边属性值\n",
    "Parameters:\n",
    "    cntrPt、parentPt - 用于计算标注位置\n",
    "    txtString - 标注的内容\n",
    "\"\"\"\n",
    "def plotMidText(cntrPt, parentPt, txtString):\n",
    "    xMid = (parentPt[0]-cntrPt[0])/2.0 + cntrPt[0]                               #计算标注位置\n",
    "    yMid = (parentPt[1]-cntrPt[1])/2.0 + cntrPt[1]\n",
    "    createPlot.ax1.text(xMid, yMid, txtString, va=\"center\", ha=\"center\", rotation=30)\n",
    " \n",
    " \n",
    "\"\"\"\n",
    "函数说明:绘制决策树\n",
    "Parameters:\n",
    "    myTree - 决策树(字典)\n",
    "    parentPt - 标注的内容\n",
    "    nodeTxt - 结点名\n",
    "\"\"\"\n",
    "def plotTree(myTree, parentPt, nodeTxt):\n",
    "    decisionNode = dict(boxstyle=\"sawtooth\", fc=\"0.8\")                                    #设置结点格式\n",
    "    leafNode = dict(boxstyle=\"round4\", fc=\"0.8\")                                          #设置叶结点格式\n",
    "    numLeafs = getNumLeafs(myTree)                                                        #获取决策树叶结点数目，决定了树的宽度\n",
    "    depth = getTreeDepth(myTree)                                                          #获取决策树层数\n",
    "    firstStr = next(iter(myTree))                                                         #下个字典\n",
    "    cntrPt = (plotTree.xOff + (1.0 + float(numLeafs))/2.0/plotTree.totalW, plotTree.yOff) #中心位置\n",
    "    plotMidText(cntrPt, parentPt, nodeTxt)                                                #标注有向边属性值\n",
    "    plotNode(firstStr, cntrPt, parentPt, decisionNode)                                    #绘制结点\n",
    "    secondDict = myTree[firstStr]                                                         #下一个字典，也就是继续绘制子结点\n",
    "    plotTree.yOff = plotTree.yOff - 1.0/plotTree.totalD                                   #y偏移\n",
    "    for key in secondDict.keys():\n",
    "        if type(secondDict[key]).__name__=='dict':                 #测试该结点是否为字典，如果不是字典，代表此结点为叶子结点\n",
    "            plotTree(secondDict[key],cntrPt,str(key))              #不是叶结点，递归调用继续绘制\n",
    "        else:                                                      #如果是叶结点，绘制叶结点，并标注有向边属性值\n",
    "            plotTree.xOff = plotTree.xOff + 1.0/plotTree.totalW\n",
    "            plotNode(secondDict[key], (plotTree.xOff, plotTree.yOff), cntrPt, leafNode)\n",
    "            plotMidText((plotTree.xOff, plotTree.yOff), cntrPt, str(key))\n",
    "    plotTree.yOff = plotTree.yOff + 1.0/plotTree.totalD\n",
    " \n",
    " \n",
    "\"\"\"\n",
    "函数说明:创建绘制面板\n",
    "Parameters:\n",
    "    inTree - 决策树(字典)\n",
    "\"\"\"\n",
    "def createPlot(inTree):\n",
    "    fig = plt.figure(1, facecolor='white')                               #创建fig\n",
    "    fig.clf()                                                            #清空fig\n",
    "    axprops = dict(xticks=[], yticks=[])\n",
    "    createPlot.ax1 = plt.subplot(111, frameon=False, **axprops)          #去掉x、y轴\n",
    "    plotTree.totalW = float(getNumLeafs(inTree))                         #获取决策树叶结点数目\n",
    "    plotTree.totalD = float(getTreeDepth(inTree))                        #获取决策树层数\n",
    "    plotTree.xOff = -0.5/plotTree.totalW; plotTree.yOff = 1.0;           #x偏移\n",
    "    plotTree(inTree, (0.5,1.0), '')                                      #绘制决策树\n",
    "    plt.show()\n",
    " \n",
    " \n",
    "if __name__=='__main__':\n",
    "    mytree={'工资': {0: {'育儿': {0: 'no', 'others': 'yes'}}, 'others': 'no'}}\n",
    "    createPlot(mytree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "222f1b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'工资': {0: {'育儿': {0: 'no', 'others': 'yes'}}, 'others': 'no'}}\n"
     ]
    }
   ],
   "source": [
    "from math import log\n",
    "    \n",
    "# 构造数据集\n",
    "def create_dataset():\n",
    "    dataset = [[1,1,2,'no'],\n",
    "               [0,1,0,'no'],\n",
    "               [1,0,0,'no'],\n",
    "               [1,1,0,'no'],\n",
    "               [0,1,1,'yes'],\n",
    "               [1,1,1,'no'],\n",
    "               [0,0,2,'yes'],\n",
    "               [0,0,1,'yes']]\n",
    "    labels = ['工资', '婚姻', '育儿']\n",
    "    return dataset, labels\n",
    "\n",
    "# 计算当前集合的Gini系数\n",
    "def calcGini(dataset):\n",
    "    # 求总样本数\n",
    "    num_of_examples = len(dataset)\n",
    "    labelCnt = {}\n",
    "    # 遍历整个样本集合\n",
    "    for example in dataset:\n",
    "        # 当前样本的标签值是该列表的最后一个元素\n",
    "        currentLabel = example[-1]\n",
    "        # 统计每个标签各出现了几次\n",
    "        if currentLabel not in labelCnt.keys():\n",
    "            labelCnt[currentLabel] = 0\n",
    "        labelCnt[currentLabel] += 1\n",
    "    # 得到了当前集合中每个标签的样本个数后，计算它们的p值\n",
    "    for key in labelCnt:\n",
    "        labelCnt[key] /= num_of_examples\n",
    "        labelCnt[key] = labelCnt[key] * labelCnt[key]\n",
    "    # 计算Gini系数\n",
    "    Gini = 1 - sum(labelCnt.values())\n",
    "    return Gini\n",
    "    \n",
    "# 提取子集合\n",
    "# 功能：从dataSet中先找到所有第axis个标签值 = value的样本\n",
    "# 然后将这些样本删去第axis个标签值，再全部提取出来成为一个新的样本集\n",
    "def create_sub_dataset(dataset, index, value):\n",
    "    sub_dataset = []\n",
    "    for example in dataset:\n",
    "        current_list = []\n",
    "        if example[index] == value:\n",
    "            current_list = example[:index]\n",
    "            current_list.extend(example[index + 1 :])\n",
    "            sub_dataset.append(current_list)\n",
    "    return sub_dataset\n",
    "\n",
    "# 将当前样本集分割成特征i取值为value的一部分和取值不为value的一部分（二分）\n",
    "def split_dataset(dataset, index, value):\n",
    "    sub_dataset1 = []\n",
    "    sub_dataset2 = []\n",
    "    for example in dataset:\n",
    "        current_list = []\n",
    "        if example[index] == value:\n",
    "            current_list = example[:index]\n",
    "            current_list.extend(example[index + 1 :])\n",
    "            sub_dataset1.append(current_list)\n",
    "        else:\n",
    "            current_list = example[:index]\n",
    "            current_list.extend(example[index + 1 :])\n",
    "            sub_dataset2.append(current_list)\n",
    "    return sub_dataset1, sub_dataset2\n",
    "\n",
    "def choose_best_feature(dataset):\n",
    "    # 特征总数\n",
    "    numFeatures = len(dataset[0]) - 1\n",
    "    # 当只有一个特征时\n",
    "    if numFeatures == 1:\n",
    "        return 0\n",
    "    # 初始化最佳基尼系数\n",
    "    bestGini = 1\n",
    "    # 初始化最优特征\n",
    "    index_of_best_feature = -1\n",
    "    # 遍历所有特征，寻找最优特征和该特征下的最优切分点\n",
    "    for i in range(numFeatures):\n",
    "        # 去重，每个属性值唯一\n",
    "        uniqueVals = set(example[i] for example in dataset)\n",
    "        # Gini字典中的每个值代表以该值对应的键作为切分点对当前集合进行划分后的Gini系数\n",
    "        Gini = {}\n",
    "        # 对于当前特征的每个取值\n",
    "        for value in uniqueVals:\n",
    "            # 先求由该值进行划分得到的两个子集\n",
    "            sub_dataset1, sub_dataset2 = split_dataset(dataset,i,value)\n",
    "            # 求两个子集占原集合的比例系数prob1 prob2\n",
    "            prob1 = len(sub_dataset1) / float(len(dataset))\n",
    "            prob2 = len(sub_dataset2) / float(len(dataset))\n",
    "            # 计算子集1的Gini系数\n",
    "            Gini_of_sub_dataset1 = calcGini(sub_dataset1)\n",
    "            # 计算子集2的Gini系数\n",
    "            Gini_of_sub_dataset2 = calcGini(sub_dataset2)\n",
    "            # 计算由当前最优切分点划分后的最终Gini系数\n",
    "            Gini[value] = prob1 * Gini_of_sub_dataset1 + prob2 * Gini_of_sub_dataset2\n",
    "            # 更新最优特征和最优切分点\n",
    "            if Gini[value] < bestGini:\n",
    "                bestGini = Gini[value]\n",
    "                index_of_best_feature = i\n",
    "                best_split_point = value\n",
    "    return index_of_best_feature, best_split_point\n",
    "    \n",
    "# 返回具有最多样本数的那个标签的值（'yes' or 'no'）\n",
    "def find_label(classList):\n",
    "    # 初始化统计各标签次数的字典\n",
    "    # 键为各标签，对应的值为标签出现的次数\n",
    "    labelCnt = {}\n",
    "    for key in classList:\n",
    "        if key not in labelCnt.keys():\n",
    "            labelCnt[key] = 0\n",
    "        labelCnt[key] += 1\n",
    "    # 将classCount按值降序排列\n",
    "    # 例如：sorted_labelCnt = {'yes': 9, 'no': 6}\n",
    "    sorted_labelCnt = sorted(labelCnt.items(), key = lambda a:a[1], reverse = True)\n",
    "    # 下面这种写法有问题\n",
    "    # sortedClassCount = sorted(labelCnt.iteritems(), key=operator.itemgetter(1), reverse=True)\n",
    "    # 取sorted_labelCnt中第一个元素中的第一个值，即为所求\n",
    "    return sorted_labelCnt[0][0]\n",
    "    \n",
    "    \n",
    "def create_decision_tree(dataset, features):\n",
    "    # 求出训练集所有样本的标签\n",
    "    # 对于初始数据集，其label_list = ['no', 'no', 'yes', 'yes', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'no']\n",
    "    label_list = [example[-1] for example in dataset]\n",
    "    # 先写两个递归结束的情况：\n",
    "    # 若当前集合的所有样本标签相等（即样本已被分“纯”）\n",
    "    # 则直接返回该标签值作为一个叶子节点\n",
    "    if label_list.count(label_list[0]) == len(label_list):\n",
    "        return label_list[0]\n",
    "    # 若训练集的所有特征都被使用完毕，当前无可用特征，但样本仍未被分“纯”\n",
    "    # 则返回所含样本最多的标签作为结果\n",
    "    if len(dataset[0]) == 1:\n",
    "        return find_label(label_list)\n",
    "    # 下面是正式建树的过程\n",
    "    # 选取进行分支的最佳特征的下标和最佳切分点\n",
    "    index_of_best_feature, best_split_point = choose_best_feature(dataset)\n",
    "    # 得到最佳特征\n",
    "    best_feature = features[index_of_best_feature]\n",
    "    # 初始化决策树\n",
    "    decision_tree = {best_feature: {}}\n",
    "    # 使用过当前最佳特征后将其删去\n",
    "    del(features[index_of_best_feature])\n",
    "    # 子特征 = 当前特征（因为刚才已经删去了用过的特征）\n",
    "    sub_labels = features[:]\n",
    "    # 递归调用create_decision_tree去生成新节点\n",
    "    # 生成由最优切分点划分出来的二分子集\n",
    "    sub_dataset1, sub_dataset2 = split_dataset(dataset,index_of_best_feature,best_split_point)\n",
    "    # 构造左子树\n",
    "    decision_tree[best_feature][best_split_point] = create_decision_tree(sub_dataset1, sub_labels)\n",
    "    # 构造右子树\n",
    "    decision_tree[best_feature]['others'] = create_decision_tree(sub_dataset2, sub_labels)\n",
    "    return decision_tree\n",
    "    \n",
    "# 用上面训练好的决策树对新样本分类\n",
    "def classify(decision_tree, features, test_example):\n",
    "    # 根节点代表的属性\n",
    "    first_feature = list(decision_tree.keys())[0]\n",
    "    # second_dict是第一个分类属性的值（也是字典）\n",
    "    second_dict = decision_tree[first_feature]\n",
    "    # 树根代表的属性，所在属性标签中的位置，即第几个属性\n",
    "    index_of_first_feature = features.index(first_feature)\n",
    "    # 对于second_dict中的每一个key\n",
    "    for key in second_dict.keys():\n",
    "        # 不等于'others'的key\n",
    "        if key != 'others':\n",
    "            if test_example[index_of_first_feature] == key:\n",
    "            # 若当前second_dict的key的value是一个字典\n",
    "                if type(second_dict[key]).__name__ == 'dict':\n",
    "                    # 则需要递归查询\n",
    "                    classLabel = classify(second_dict[key], features, test_example)\n",
    "                # 若当前second_dict的key的value是一个单独的值\n",
    "                else:\n",
    "                    # 则就是要找的标签值\n",
    "                    classLabel = second_dict[key]\n",
    "            # 如果测试样本在当前特征的取值不等于key，就说明它在当前特征的取值属于'others'\n",
    "            else:\n",
    "                # 如果second_dict['others']的值是个字符串，则直接输出\n",
    "                if isinstance(second_dict['others'],str):\n",
    "                    classLabel = second_dict['others']\n",
    "                # 如果second_dict['others']的值是个字典，则递归查询\n",
    "                else:\n",
    "                    classLabel = classify(second_dict['others'], features, test_example)\n",
    "    return classLabel\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    dataset, features = create_dataset()\n",
    "    decision_tree = create_decision_tree(dataset, features)\n",
    "    # 打印生成的决策树\n",
    "    print(decision_tree)\n",
    "    # 对新样本进行分类测试\n",
    "    #features = ['age', 'work', 'house', 'credit']\n",
    "    #test_example = ['midlife', 'yes', 'no', 'great']\n",
    "    #print(classify(decision_tree, features, test_example))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab01e0e0",
   "metadata": {},
   "source": [
    "$accuracy=\\frac{TP+TN}{TP+TN+FP+FN}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ca5b4c",
   "metadata": {},
   "source": [
    "$macroF1 = \\frac{2\\times macroP\\times macroR}{macroP+macroR}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cfe7b3",
   "metadata": {},
   "source": [
    "$$macroP = \\frac{1}{n}\\sum^n_1P_i$$\n",
    "$$macroR = \\frac{1}{n}\\sum^n_1R_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6f47a3",
   "metadata": {},
   "source": [
    "$FPS = \\frac{frameNum}{elapsedTime}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2035b99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ML] *",
   "language": "python",
   "name": "conda-env-ML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
